2022-06-14 14:20:15 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 14:20:15 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 14:20:15 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 14:20:15 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655191215682
2022-06-14 14:20:15 [main] INFO  ReadCSV:21 - Starting load...
2022-06-14 14:20:15 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 14:20:16 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 14:20:16 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 14:20:16 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 14:20:16 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 14:20:16 [main] INFO  ReadCSV:29 - Finish
2022-06-14 14:31:11 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 14:31:12 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 14:31:12 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 14:31:12 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655191872104
2022-06-14 14:31:12 [main] INFO  ReadCSV:21 - Starting load...
2022-06-14 14:31:12 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 14:31:12 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 14:31:12 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 14:31:12 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 14:31:12 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 14:31:12 [main] INFO  ReadCSV:29 - Finish
2022-06-14 14:35:55 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 14:35:55 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 14:35:55 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 14:35:55 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655192155173
2022-06-14 14:35:55 [main] INFO  ReadCSV:21 - Starting load...
2022-06-14 14:35:55 [main] INFO  ReadCSV:24 - Start Processing data/customer.csv
2022-06-14 14:35:55 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 14:35:55 [main] INFO  ReadCSV:34 - Finished Sending 16messages from data/customer.csv
2022-06-14 14:35:55 [main] INFO  ReadCSV:24 - Start Processing data/customer1.csv
2022-06-14 14:35:55 [main] INFO  ReadCSV:34 - Finished Sending 6messages from data/customer1.csv
2022-06-14 14:35:55 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 14:35:55 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 14:35:55 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 14:35:55 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 14:35:55 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 14:35:55 [main] INFO  ReadCSV:29 - Finish
2022-06-14 14:52:31 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-14 14:52:31 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 14:52:31 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 14:52:31 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655193151177
2022-06-14 14:52:31 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-14 14:52:31 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 14:52:31 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-14 14:52:31 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 14:52:31 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 14:52:31 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=1, memberId='demo-767f3c5a-dee4-4539-a3f8-731eee113b0c', protocol='range'}
2022-06-14 14:52:31 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 1: {demo-767f3c5a-dee4-4539-a3f8-731eee113b0c=Assignment(partitions=[customer-0])}
2022-06-14 14:52:31 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=1, memberId='demo-767f3c5a-dee4-4539-a3f8-731eee113b0c', protocol='range'}
2022-06-14 14:52:31 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-14 14:52:31 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-14 14:52:31 [main] INFO  ConsumerCoordinator:1362 - [Consumer clientId=demo, groupId=test-consumer-group] Found no committed offset for partition customer-0
2022-06-14 14:52:31 [main] INFO  SubscriptionState:398 - [Consumer clientId=demo, groupId=test-consumer-group] Resetting offset for partition customer-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}.
2022-06-14 15:13:27 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-14 15:13:27 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 15:13:27 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 15:13:27 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655194407922
2022-06-14 15:13:27 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-14 15:13:28 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 15:13:28 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-14 15:13:28 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 15:13:28 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 15:13:33 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=2, memberId='demo-a639b93d-c5e3-4177-ad04-498c2f86362b', protocol='range'}
2022-06-14 15:13:33 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 2: {demo-a639b93d-c5e3-4177-ad04-498c2f86362b=Assignment(partitions=[customer-0])}
2022-06-14 15:13:33 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=2, memberId='demo-a639b93d-c5e3-4177-ad04-498c2f86362b', protocol='range'}
2022-06-14 15:13:33 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-14 15:13:33 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-14 15:13:33 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-14 15:26:21 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-14 15:26:22 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 15:26:22 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 15:26:22 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655195181999
2022-06-14 15:26:22 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-14 15:26:22 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 15:26:22 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-14 15:26:22 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 15:26:22 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 15:26:22 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=4, memberId='demo-c0ec09ef-4e0c-495e-b51c-f5bd791feec2', protocol='range'}
2022-06-14 15:26:22 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 4: {demo-c0ec09ef-4e0c-495e-b51c-f5bd791feec2=Assignment(partitions=[customer-0])}
2022-06-14 15:26:22 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=4, memberId='demo-c0ec09ef-4e0c-495e-b51c-f5bd791feec2', protocol='range'}
2022-06-14 15:26:22 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-14 15:26:22 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-14 15:26:22 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-14 15:28:21 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-14 15:28:21 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 15:28:21 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 15:28:21 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655195301718
2022-06-14 15:28:21 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-14 15:28:22 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 15:28:22 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-14 15:28:22 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 15:28:22 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 15:28:26 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=5, memberId='demo-b89e24ec-47c6-4435-863f-0f98f3d22c08', protocol='range'}
2022-06-14 15:28:26 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 5: {demo-b89e24ec-47c6-4435-863f-0f98f3d22c08=Assignment(partitions=[customer-0])}
2022-06-14 15:28:26 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=5, memberId='demo-b89e24ec-47c6-4435-863f-0f98f3d22c08', protocol='range'}
2022-06-14 15:28:26 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-14 15:28:26 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-14 15:28:26 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-14 15:28:31 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-14 15:28:31 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-b89e24ec-47c6-4435-863f-0f98f3d22c08 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-14 15:28:31 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 15:28:31 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 15:28:31 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 15:28:31 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-14 22:57:26 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 22:57:27 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 22:57:27 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 22:57:27 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655222247023
2022-06-14 22:57:27 [main] INFO  CSVProducer:31 - Starting load...
2022-06-14 22:57:27 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 23:11:50 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:11:50 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:11:50 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:11:50 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655223110623
2022-06-14 23:11:50 [main] INFO  CSVProducer:42 - Starting load...
2022-06-14 23:11:50 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:11:51 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:11:51 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:11:51 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:11:51 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:11:51 [main] INFO  CSVProducer:45 - Finish
2022-06-14 23:14:28 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:14:28 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:14:28 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:14:28 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655223268593
2022-06-14 23:14:28 [main] INFO  CSVProducer:44 - Starting load...
2022-06-14 23:14:28 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:14:29 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:14:29 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:14:29 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:14:29 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:14:29 [main] INFO  CSVProducer:47 - Finish
2022-06-14 23:14:51 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:14:51 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:14:51 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:14:51 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655223291486
2022-06-14 23:14:51 [main] INFO  CSVProducer:44 - Starting load...
2022-06-14 23:14:51 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:14:52 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:14:52 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:14:52 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:14:52 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:14:52 [main] INFO  CSVProducer:47 - Finish
2022-06-14 23:16:16 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:16:16 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:16:16 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:16:16 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655223376554
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - id
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - num_order
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - age
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - telephone
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 1
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 120
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 22
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 0367716286
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 2
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 90
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 45
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 0379160207
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 3
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 145
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 34
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 0399538068
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 4
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 300
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 18
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 0387006279
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 5
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 130
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 10
2022-06-14 23:16:16 [main] INFO  CSVProducer:36 - 0373543099
2022-06-14 23:16:16 [main] INFO  CSVProducer:45 - Starting load...
2022-06-14 23:16:16 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:16:17 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:16:17 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:16:17 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:16:17 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:16:17 [main] INFO  CSVProducer:48 - Finish
2022-06-14 23:17:33 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:17:33 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:17:33 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:17:33 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655223453228
2022-06-14 23:17:33 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - id
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - num_order
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - age
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - telephone
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 1
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 120
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 22
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 0367716286
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 2
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 90
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 45
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 0379160207
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 3
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 145
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 34
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 0399538068
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 4
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 300
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 18
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 0387006279
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 5
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 130
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 10
2022-06-14 23:17:33 [main] INFO  CSVProducer:36 - 0373543099
2022-06-14 23:17:33 [main] INFO  CSVProducer:45 - Starting load...
2022-06-14 23:17:33 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:17:33 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:17:33 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:17:33 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:17:33 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:17:33 [main] INFO  CSVProducer:48 - Finish
2022-06-14 23:34:33 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:34:33 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:34:33 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:34:33 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655224473607
2022-06-14 23:34:33 [main] INFO  CSVProducer:53 - Starting load...
2022-06-14 23:34:33 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:34:34 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:34:34 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:34:34 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:34:34 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:34:34 [main] INFO  CSVProducer:56 - Finish
2022-06-14 23:35:31 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:35:31 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:35:31 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:35:31 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655224531299
2022-06-14 23:35:31 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - id
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - num_order
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - age
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - telephone
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 1
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 120
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 22
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 0367716286
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 2
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 90
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 45
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 0379160207
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 3
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 145
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 34
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 0399538068
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 4
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 300
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 18
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 0387006279
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 5
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 130
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 10
2022-06-14 23:35:31 [main] INFO  CSVProducer:38 - 0373543099
2022-06-14 23:35:31 [main] INFO  CSVProducer:53 - Starting load...
2022-06-14 23:35:32 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:35:32 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:35:32 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:35:32 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:35:32 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:35:32 [main] INFO  CSVProducer:56 - Finish
2022-06-14 23:36:34 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:36:34 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:36:34 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:36:34 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655224594756
2022-06-14 23:36:35 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 23:36:35 [main] INFO  CSVProducer:36 - id,num_order,age,telephone
2022-06-14 23:36:35 [main] INFO  CSVProducer:36 - 1,120,22,0367716286
2022-06-14 23:36:35 [main] INFO  CSVProducer:36 - 2,90,45,0379160207
2022-06-14 23:36:35 [main] INFO  CSVProducer:36 - 3,145,34,0399538068
2022-06-14 23:36:35 [main] INFO  CSVProducer:36 - 4,300,18,0387006279
2022-06-14 23:36:35 [main] INFO  CSVProducer:36 - 5,130,10,0373543099
2022-06-14 23:36:35 [main] INFO  CSVProducer:50 - Starting load...
2022-06-14 23:36:35 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:36:35 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:36:35 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:36:35 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:36:35 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:36:35 [main] INFO  CSVProducer:53 - Finish
2022-06-14 23:37:34 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-14 23:37:35 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:37:35 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:37:35 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655224654993
2022-06-14 23:37:35 [main] INFO  CSVProducer:27 - Starting load...
2022-06-14 23:37:35 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - id,num_order,age,telephone
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 1,120,22,0367716286
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 2,90,45,0379160207
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 3,145,34,0399538068
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 4,300,18,0387006279
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 5,130,10,0373543099
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 6,90,17,0336528479
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 7,400,30,0347597599
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 8,10,31,0398290980
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 9,230,15,0375667337
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 10,60,14,0326138799
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 11,105,9,0344623488
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 12,222,40,0352372889
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 13,78,51,0867556771
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 14,123,19,0376130794
2022-06-14 23:37:35 [main] INFO  CSVProducer:36 - 15,56,13,0372850979
2022-06-14 23:37:35 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-14 23:37:35 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-14 23:37:35 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-14 23:37:35 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-14 23:37:35 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-14 23:37:35 [main] INFO  CSVProducer:50 - Finish
2022-06-14 23:52:14 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-14 23:52:14 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-14 23:52:14 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-14 23:52:14 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655225534273
2022-06-14 23:52:14 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-14 23:52:14 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-14 23:52:14 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-14 23:52:14 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 23:52:14 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-14 23:52:14 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=7, memberId='demo-f742f071-bdde-40d0-adac-b81ba733b2c8', protocol='range'}
2022-06-14 23:52:14 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 7: {demo-f742f071-bdde-40d0-adac-b81ba733b2c8=Assignment(partitions=[customer-0])}
2022-06-14 23:52:14 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=7, memberId='demo-f742f071-bdde-40d0-adac-b81ba733b2c8', protocol='range'}
2022-06-14 23:52:14 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-14 23:52:14 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-14 23:52:14 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-14 23:52:15 [main] INFO  ReadCSV:33 - 4,300,18,0387006279
2022-06-14 23:52:15 [main] INFO  ReadCSV:33 - 5,130,10,0373543099
2022-06-14 23:52:15 [main] INFO  ReadCSV:33 - 4,300,18,0387006279
2022-06-14 23:52:15 [main] INFO  ReadCSV:33 - 5,130,10,0373543099
2022-06-14 23:52:15 [main] INFO  ReadCSV:33 - 9,230,15,0375667337
2022-06-14 23:52:15 [main] INFO  ReadCSV:33 - 11,105,9,0344623488
2022-06-14 23:52:15 [main] INFO  ReadCSV:33 - 14,123,19,0376130794
2022-06-15 00:47:35 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 00:47:35 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 00:47:35 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 00:47:35 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655228855842
2022-06-15 00:47:35 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 00:47:35 [main] INFO  ReadCSV:38 - Waiting for data...
2022-06-15 00:47:36 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 00:47:36 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 00:47:36 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:47:36 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:47:40 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=8, memberId='demo-55de0642-4c80-4c98-b6ef-0dbd3f5141b7', protocol='range'}
2022-06-15 00:47:40 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 8: {demo-55de0642-4c80-4c98-b6ef-0dbd3f5141b7=Assignment(partitions=[customer-0])}
2022-06-15 00:47:40 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=8, memberId='demo-55de0642-4c80-4c98-b6ef-0dbd3f5141b7', protocol='range'}
2022-06-15 00:47:40 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 00:47:40 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 00:47:40 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 00:49:03 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 00:49:04 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 00:49:04 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 00:49:04 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655228944014
2022-06-15 00:49:04 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 00:49:04 [main] INFO  ReadCSV:38 - Waiting for data...
2022-06-15 00:49:04 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 00:49:04 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 00:49:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:49:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:49:08 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=9, memberId='demo-79e234cc-e2cb-45c8-9e5a-e9589824715f', protocol='range'}
2022-06-15 00:49:08 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 9: {demo-79e234cc-e2cb-45c8-9e5a-e9589824715f=Assignment(partitions=[customer-0])}
2022-06-15 00:49:08 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=9, memberId='demo-79e234cc-e2cb-45c8-9e5a-e9589824715f', protocol='range'}
2022-06-15 00:49:08 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 00:49:08 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 00:49:08 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 00:50:00 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 00:50:00 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 00:50:00 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 00:50:00 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229000738
2022-06-15 00:50:00 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 00:50:00 [main] INFO  ReadCSV:38 - Waiting for data...
2022-06-15 00:50:01 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 00:50:01 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 00:50:01 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:50:01 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:50:03 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=10, memberId='demo-11928e29-3223-4379-901b-bb13b28e0ff5', protocol='range'}
2022-06-15 00:50:03 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 10: {demo-11928e29-3223-4379-901b-bb13b28e0ff5=Assignment(partitions=[customer-0])}
2022-06-15 00:50:03 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=10, memberId='demo-11928e29-3223-4379-901b-bb13b28e0ff5', protocol='range'}
2022-06-15 00:50:03 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 00:50:03 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 00:50:03 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 00:53:18 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 00:53:18 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 00:53:18 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 00:53:18 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229198211
2022-06-15 00:53:18 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 00:53:18 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 00:53:18 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 00:53:18 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:53:18 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:53:22 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=11, memberId='demo-cefe8f6b-044b-402d-ad6c-ba2560e0d95b', protocol='range'}
2022-06-15 00:53:22 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 11: {demo-cefe8f6b-044b-402d-ad6c-ba2560e0d95b=Assignment(partitions=[customer-0])}
2022-06-15 00:53:22 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=11, memberId='demo-cefe8f6b-044b-402d-ad6c-ba2560e0d95b', protocol='range'}
2022-06-15 00:53:22 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 00:53:22 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 00:53:22 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 00:56:01 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 00:56:01 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 00:56:01 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 00:56:01 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229361459
2022-06-15 00:56:01 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 00:56:02 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 00:56:02 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 00:56:02 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:56:02 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:56:02 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-39800e04-89d0-4223-90aa-fd0bcaeb61e9 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-15 00:56:05 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 00:56:05 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 00:56:05 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 00:56:05 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-15 00:57:05 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 00:57:06 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 00:57:06 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 00:57:06 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229426135
2022-06-15 00:57:06 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 00:57:06 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 00:57:06 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 00:57:06 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:57:06 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 00:57:06 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=14, memberId='demo-49a471e0-6392-42dd-b272-ce7fa07fe400', protocol='range'}
2022-06-15 00:57:06 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 14: {demo-49a471e0-6392-42dd-b272-ce7fa07fe400=Assignment(partitions=[customer-0])}
2022-06-15 00:57:06 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=14, memberId='demo-49a471e0-6392-42dd-b272-ce7fa07fe400', protocol='range'}
2022-06-15 00:57:06 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 00:57:06 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 00:57:06 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:02:54 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:02:54 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:02:54 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:02:54 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229774192
2022-06-15 01:02:54 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:02:55 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:02:55 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:02:55 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:02:55 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:02:58 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=15, memberId='demo-de8cf82a-3f0d-46da-8886-6a9834710734', protocol='range'}
2022-06-15 01:02:58 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 15: {demo-de8cf82a-3f0d-46da-8886-6a9834710734=Assignment(partitions=[customer-0])}
2022-06-15 01:02:58 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=15, memberId='demo-de8cf82a-3f0d-46da-8886-6a9834710734', protocol='range'}
2022-06-15 01:02:58 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:02:58 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:02:58 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:04:27 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:04:28 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:04:28 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:04:28 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229868136
2022-06-15 01:04:28 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:04:28 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:04:28 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:04:28 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:04:28 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:04:29 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=16, memberId='demo-d2c37c80-742c-4a0c-a33e-0b492303917b', protocol='range'}
2022-06-15 01:04:29 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 16: {demo-d2c37c80-742c-4a0c-a33e-0b492303917b=Assignment(partitions=[customer-0])}
2022-06-15 01:04:29 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=16, memberId='demo-d2c37c80-742c-4a0c-a33e-0b492303917b', protocol='range'}
2022-06-15 01:04:29 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:04:29 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:04:30 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:05:23 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:05:23 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:05:23 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:05:23 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229923322
2022-06-15 01:05:23 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:05:23 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:05:23 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:05:23 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:05:23 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:05:24 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=17, memberId='demo-b9f480fa-a42f-4238-a9da-3e4021f1707c', protocol='range'}
2022-06-15 01:05:25 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 17: {demo-b9f480fa-a42f-4238-a9da-3e4021f1707c=Assignment(partitions=[customer-0])}
2022-06-15 01:05:25 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=17, memberId='demo-b9f480fa-a42f-4238-a9da-3e4021f1707c', protocol='range'}
2022-06-15 01:05:25 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:05:25 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:05:25 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=92, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:05:41 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-15 01:05:41 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:05:41 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:05:41 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655229941426
2022-06-15 01:05:41 [main] INFO  CSVProducer:27 - Starting load...
2022-06-15 01:05:42 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - id,num_order,age,telephone
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 1,120,22,0367716286
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 2,90,45,0379160207
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 3,145,34,0399538068
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 4,300,18,0387006279
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 5,130,10,0373543099
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 6,90,17,0336528479
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 7,400,30,0347597599
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 8,10,31,0398290980
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 9,230,15,0375667337
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 10,60,14,0326138799
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 11,105,9,0344623488
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 12,222,40,0352372889
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 13,78,51,0867556771
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 14,123,19,0376130794
2022-06-15 01:05:42 [main] INFO  CSVProducer:36 - 15,56,13,0372850979
2022-06-15 01:05:42 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-15 01:05:42 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 01:05:42 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 01:05:42 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 01:05:42 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-15 01:05:42 [main] INFO  CSVProducer:42 - Finish
2022-06-15 01:11:06 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:11:07 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:11:07 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:11:07 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655230267035
2022-06-15 01:11:07 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:11:07 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:11:07 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:11:07 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:11:07 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:11:11 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=18, memberId='demo-63807a5b-f21c-441a-9593-05e855429dcd', protocol='range'}
2022-06-15 01:11:11 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 18: {demo-63807a5b-f21c-441a-9593-05e855429dcd=Assignment(partitions=[customer-0])}
2022-06-15 01:11:11 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=18, memberId='demo-63807a5b-f21c-441a-9593-05e855429dcd', protocol='range'}
2022-06-15 01:11:11 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:11:11 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:11:11 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:17:26 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:17:26 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:17:26 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:17:26 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655230646703
2022-06-15 01:17:26 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:17:27 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:17:27 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:17:27 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:17:27 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:17:27 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=20, memberId='demo-fcba81e0-8b66-46ce-a6fa-fcc9d752b426', protocol='range'}
2022-06-15 01:17:27 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 20: {demo-fcba81e0-8b66-46ce-a6fa-fcc9d752b426=Assignment(partitions=[customer-0])}
2022-06-15 01:17:27 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=20, memberId='demo-fcba81e0-8b66-46ce-a6fa-fcc9d752b426', protocol='range'}
2022-06-15 01:17:27 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:17:27 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:17:27 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:25:08 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:25:08 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:25:08 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:25:08 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655231108866
2022-06-15 01:25:08 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:25:09 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:25:09 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:25:09 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:25:09 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:25:09 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=22, memberId='demo-d7d60d73-29dc-4c19-ada2-a711cee83c28', protocol='range'}
2022-06-15 01:25:09 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 22: {demo-d7d60d73-29dc-4c19-ada2-a711cee83c28=Assignment(partitions=[customer-0])}
2022-06-15 01:25:09 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=22, memberId='demo-d7d60d73-29dc-4c19-ada2-a711cee83c28', protocol='range'}
2022-06-15 01:25:09 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:25:09 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:25:09 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:26:15 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:26:16 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:26:16 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:26:16 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655231176030
2022-06-15 01:26:16 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:26:16 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:26:16 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:26:16 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:26:16 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:26:16 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=24, memberId='demo-3615e918-4ca5-433d-b795-344aae4f13b0', protocol='range'}
2022-06-15 01:26:16 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 24: {demo-3615e918-4ca5-433d-b795-344aae4f13b0=Assignment(partitions=[customer-0])}
2022-06-15 01:26:16 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=24, memberId='demo-3615e918-4ca5-433d-b795-344aae4f13b0', protocol='range'}
2022-06-15 01:26:16 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:26:16 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:26:16 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:27:38 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:27:38 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:27:38 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:27:38 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655231258293
2022-06-15 01:27:38 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:27:38 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:27:38 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:27:38 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:27:38 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:27:38 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=26, memberId='demo-d069b0e9-d1fd-4134-8671-d70358c58444', protocol='range'}
2022-06-15 01:27:38 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 26: {demo-d069b0e9-d1fd-4134-8671-d70358c58444=Assignment(partitions=[customer-0])}
2022-06-15 01:27:38 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=26, memberId='demo-d069b0e9-d1fd-4134-8671-d70358c58444', protocol='range'}
2022-06-15 01:27:38 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:27:38 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:27:38 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:33:53 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:33:54 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:33:54 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:33:54 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655231634124
2022-06-15 01:33:54 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:33:54 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:33:54 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:33:54 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:33:54 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:33:54 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=28, memberId='demo-ed9a6363-2d47-42d7-bce2-2e3a63be28de', protocol='range'}
2022-06-15 01:33:54 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 28: {demo-ed9a6363-2d47-42d7-bce2-2e3a63be28de=Assignment(partitions=[customer-0])}
2022-06-15 01:33:54 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=28, memberId='demo-ed9a6363-2d47-42d7-bce2-2e3a63be28de', protocol='range'}
2022-06-15 01:33:54 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:33:54 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:33:54 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 01:34:57 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 01:34:57 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 01:34:57 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 01:34:57 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655231697572
2022-06-15 01:34:57 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 01:34:58 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 01:34:58 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 01:34:58 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:34:58 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 01:34:58 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=30, memberId='demo-0c37ee66-68e0-440b-9537-7edaca4b3118', protocol='range'}
2022-06-15 01:34:58 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 30: {demo-0c37ee66-68e0-440b-9537-7edaca4b3118=Assignment(partitions=[customer-0])}
2022-06-15 01:34:58 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=30, memberId='demo-0c37ee66-68e0-440b-9537-7edaca4b3118', protocol='range'}
2022-06-15 01:34:58 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 01:34:58 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 01:34:58 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 21:54:57 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-15 21:54:57 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 21:54:57 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 21:54:57 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655304897657
2022-06-15 21:54:57 [main] INFO  ReadCSV:21 - Starting load...
2022-06-15 21:54:57 [main] INFO  ReadCSV:24 - Start Processing data/customer.csv
2022-06-15 21:54:58 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 21:54:58 [main] INFO  ReadCSV:34 - Finished Sending 16messages from data/customer.csv
2022-06-15 21:54:58 [main] INFO  ReadCSV:24 - Start Processing data/customer1.csv
2022-06-15 21:54:58 [main] INFO  ReadCSV:34 - Finished Sending 6messages from data/customer1.csv
2022-06-15 21:54:58 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-15 21:54:58 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 21:54:58 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 21:54:58 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 21:54:58 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-15 21:54:58 [main] INFO  ReadCSV:29 - Finish
2022-06-15 22:07:00 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:07:01 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:07:01 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:07:01 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655305621154
2022-06-15 22:07:01 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:07:01 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:07:01 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:07:01 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:07:01 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:07:01 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=32, memberId='demo-4420cf43-c853-46ce-ab1a-fea1aeff3bb1', protocol='range'}
2022-06-15 22:07:01 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 32: {demo-4420cf43-c853-46ce-ab1a-fea1aeff3bb1=Assignment(partitions=[customer-0])}
2022-06-15 22:07:01 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=32, memberId='demo-4420cf43-c853-46ce-ab1a-fea1aeff3bb1', protocol='range'}
2022-06-15 22:07:01 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:07:01 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:07:01 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:10:57 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:10:57 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:10:57 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:10:57 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655305857399
2022-06-15 22:10:57 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:10:57 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:10:57 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:10:57 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:10:57 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:10:57 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=34, memberId='demo-d0e9a21a-a5de-4093-985a-5c3896b37e8e', protocol='range'}
2022-06-15 22:10:57 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 34: {demo-d0e9a21a-a5de-4093-985a-5c3896b37e8e=Assignment(partitions=[customer-0])}
2022-06-15 22:10:57 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=34, memberId='demo-d0e9a21a-a5de-4093-985a-5c3896b37e8e', protocol='range'}
2022-06-15 22:10:57 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:10:58 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:10:58 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:11:06 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-15 22:11:06 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:11:06 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:11:06 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655305866333
2022-06-15 22:11:06 [main] INFO  CSVProducer:27 - Starting load...
2022-06-15 22:11:06 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - id,num_order,age,telephone
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 1,120,22,0367716286
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 2,90,45,0379160207
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 3,145,34,0399538068
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 4,300,18,0387006279
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 5,130,10,0373543099
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 6,90,17,0336528479
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 7,400,30,0347597599
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 8,10,31,0398290980
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 9,230,15,0375667337
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 10,60,14,0326138799
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 11,105,9,0344623488
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 12,222,40,0352372889
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 13,78,51,0867556771
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 14,123,19,0376130794
2022-06-15 22:11:06 [main] INFO  CSVProducer:36 - 15,56,13,0372850979
2022-06-15 22:11:06 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-15 22:11:06 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 22:11:06 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 22:11:06 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 22:11:06 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-15 22:11:06 [main] INFO  CSVProducer:42 - Finish
2022-06-15 22:32:39 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:32:39 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:32:39 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:32:39 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655307159720
2022-06-15 22:32:39 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:32:40 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:32:40 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:32:40 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:32:40 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:32:40 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=36, memberId='demo-dc6fb4ee-cac0-4a1c-9ffe-e86e5ae088de', protocol='range'}
2022-06-15 22:32:40 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 36: {demo-dc6fb4ee-cac0-4a1c-9ffe-e86e5ae088de=Assignment(partitions=[customer-0])}
2022-06-15 22:32:40 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=36, memberId='demo-dc6fb4ee-cac0-4a1c-9ffe-e86e5ae088de', protocol='range'}
2022-06-15 22:32:40 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:32:40 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:32:40 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:34:58 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:34:58 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:34:58 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:34:58 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655307298473
2022-06-15 22:34:58 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:34:59 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:34:59 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:34:59 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:34:59 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:34:59 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=38, memberId='demo-7db72ac3-0434-4eb3-abc9-008c7cf04325', protocol='range'}
2022-06-15 22:34:59 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 38: {demo-7db72ac3-0434-4eb3-abc9-008c7cf04325=Assignment(partitions=[customer-0])}
2022-06-15 22:34:59 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=38, memberId='demo-7db72ac3-0434-4eb3-abc9-008c7cf04325', protocol='range'}
2022-06-15 22:34:59 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:34:59 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:34:59 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:39:24 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-15 22:39:24 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:39:24 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:39:24 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655307564513
2022-06-15 22:39:24 [main] INFO  CSVProducer:27 - Starting load...
2022-06-15 22:39:25 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-15 22:39:25 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-15 22:39:25 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-15 22:39:25 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 22:39:25 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 22:39:25 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 22:39:25 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-15 22:39:25 [main] INFO  CSVProducer:41 - Finish
2022-06-15 22:40:33 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:40:33 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:40:33 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:40:33 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655307633766
2022-06-15 22:40:33 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:40:34 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:40:34 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:40:34 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:40:34 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:40:34 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=40, memberId='demo-868c9bef-c83d-4215-aaf9-b46b84dd1bd2', protocol='range'}
2022-06-15 22:40:34 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 40: {demo-868c9bef-c83d-4215-aaf9-b46b84dd1bd2=Assignment(partitions=[customer-0])}
2022-06-15 22:40:34 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=40, memberId='demo-868c9bef-c83d-4215-aaf9-b46b84dd1bd2', protocol='range'}
2022-06-15 22:40:34 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:40:34 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:40:34 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:43:12 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:43:12 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:43:12 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:43:12 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655307792986
2022-06-15 22:43:13 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:43:13 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:43:13 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:43:13 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:43:13 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:43:13 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=42, memberId='demo-15c4e782-fda4-4372-abf7-76d09aba720e', protocol='range'}
2022-06-15 22:43:13 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 42: {demo-15c4e782-fda4-4372-abf7-76d09aba720e=Assignment(partitions=[customer-0])}
2022-06-15 22:43:13 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=42, memberId='demo-15c4e782-fda4-4372-abf7-76d09aba720e', protocol='range'}
2022-06-15 22:43:13 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:43:13 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:43:13 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:47:29 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-15 22:47:29 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:47:29 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:47:29 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308049832
2022-06-15 22:47:29 [main] INFO  CSVProducer:27 - Starting load...
2022-06-15 22:47:30 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:47:30 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-15 22:47:30 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-15 22:47:30 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-15 22:47:30 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-15 22:47:30 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-15 22:47:30 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-15 22:47:30 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-15 22:47:30 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 22:47:30 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 22:47:30 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 22:47:30 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-15 22:47:30 [main] INFO  CSVProducer:41 - Finish
2022-06-15 22:47:56 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:47:56 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:47:56 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:47:56 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308076287
2022-06-15 22:47:56 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:47:56 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:47:56 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:47:56 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:47:56 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:47:56 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=44, memberId='demo-c7ebee16-3648-4d4b-8662-011749dd003e', protocol='range'}
2022-06-15 22:47:56 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 44: {demo-c7ebee16-3648-4d4b-8662-011749dd003e=Assignment(partitions=[customer-0])}
2022-06-15 22:47:56 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=44, memberId='demo-c7ebee16-3648-4d4b-8662-011749dd003e', protocol='range'}
2022-06-15 22:47:56 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:47:56 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:47:56 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:48:12 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:48:12 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:48:12 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:48:12 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308092390
2022-06-15 22:48:12 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:48:12 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:48:12 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:48:12 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:48:12 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:48:12 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=46, memberId='demo-e1091c06-d12b-4ebc-89d7-798bc8496895', protocol='range'}
2022-06-15 22:48:12 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 46: {demo-e1091c06-d12b-4ebc-89d7-798bc8496895=Assignment(partitions=[customer-0])}
2022-06-15 22:48:12 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=46, memberId='demo-e1091c06-d12b-4ebc-89d7-798bc8496895', protocol='range'}
2022-06-15 22:48:12 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:48:12 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:48:13 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:51:01 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:51:01 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:51:01 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:51:01 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308261913
2022-06-15 22:51:01 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:51:02 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:51:02 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:51:02 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:51:02 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:51:02 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=48, memberId='demo-2015be96-9503-4823-b22e-28775b647dee', protocol='range'}
2022-06-15 22:51:02 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 48: {demo-2015be96-9503-4823-b22e-28775b647dee=Assignment(partitions=[customer-0])}
2022-06-15 22:51:02 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=48, memberId='demo-2015be96-9503-4823-b22e-28775b647dee', protocol='range'}
2022-06-15 22:51:02 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:51:02 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:51:02 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:53:14 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:53:14 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:53:14 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:53:14 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308394195
2022-06-15 22:53:14 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:53:14 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:53:14 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:53:14 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:53:14 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:53:14 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=50, memberId='demo-56e30dc4-5ce7-402e-ba69-74c3c40ccbec', protocol='range'}
2022-06-15 22:53:14 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 50: {demo-56e30dc4-5ce7-402e-ba69-74c3c40ccbec=Assignment(partitions=[customer-0])}
2022-06-15 22:53:14 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=50, memberId='demo-56e30dc4-5ce7-402e-ba69-74c3c40ccbec', protocol='range'}
2022-06-15 22:53:14 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:53:14 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:53:14 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:54:27 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:54:27 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:54:27 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:54:27 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308467845
2022-06-15 22:54:27 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:54:28 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:54:28 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:54:28 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:54:28 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:54:28 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=52, memberId='demo-3fe8e4e5-f811-4ea6-a351-0649160ca22a', protocol='range'}
2022-06-15 22:54:28 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 52: {demo-3fe8e4e5-f811-4ea6-a351-0649160ca22a=Assignment(partitions=[customer-0])}
2022-06-15 22:54:28 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=52, memberId='demo-3fe8e4e5-f811-4ea6-a351-0649160ca22a', protocol='range'}
2022-06-15 22:54:28 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:54:28 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:54:28 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 22:56:36 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 22:56:36 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 22:56:36 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 22:56:36 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308596881
2022-06-15 22:56:36 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 22:56:37 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 22:56:37 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 22:56:37 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:56:37 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 22:56:37 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=54, memberId='demo-c7ff1cbc-fc21-42d9-acfe-62988bc83f66', protocol='range'}
2022-06-15 22:56:37 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 54: {demo-c7ff1cbc-fc21-42d9-acfe-62988bc83f66=Assignment(partitions=[customer-0])}
2022-06-15 22:56:37 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=54, memberId='demo-c7ff1cbc-fc21-42d9-acfe-62988bc83f66', protocol='range'}
2022-06-15 22:56:37 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 22:56:37 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 22:56:37 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:00:12 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:00:12 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:00:12 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:00:12 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655308812608
2022-06-15 23:00:12 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:00:13 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:00:13 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:00:13 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:00:13 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:00:13 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=56, memberId='demo-b231d477-e963-4de8-a925-43f2454c2fc9', protocol='range'}
2022-06-15 23:00:13 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 56: {demo-b231d477-e963-4de8-a925-43f2454c2fc9=Assignment(partitions=[customer-0])}
2022-06-15 23:00:13 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=56, memberId='demo-b231d477-e963-4de8-a925-43f2454c2fc9', protocol='range'}
2022-06-15 23:00:13 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:00:13 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:00:13 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:08:33 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:08:33 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:08:33 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:08:33 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655309313444
2022-06-15 23:08:33 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:08:33 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:08:33 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:08:33 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:08:33 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:08:33 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=58, memberId='demo-632fc1ca-7f66-400d-a44a-6a4c4e6bfdb5', protocol='range'}
2022-06-15 23:08:34 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 58: {demo-632fc1ca-7f66-400d-a44a-6a4c4e6bfdb5=Assignment(partitions=[customer-0])}
2022-06-15 23:08:34 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=58, memberId='demo-632fc1ca-7f66-400d-a44a-6a4c4e6bfdb5', protocol='range'}
2022-06-15 23:08:34 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:08:34 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:08:34 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:13:03 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:13:03 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:13:03 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:13:03 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655309583858
2022-06-15 23:13:03 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:13:04 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:13:04 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:13:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:13:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:13:04 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=60, memberId='demo-7fb9f4da-8e8a-4c22-b1a5-9b65bd644da3', protocol='range'}
2022-06-15 23:13:04 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 60: {demo-7fb9f4da-8e8a-4c22-b1a5-9b65bd644da3=Assignment(partitions=[customer-0])}
2022-06-15 23:13:04 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=60, memberId='demo-7fb9f4da-8e8a-4c22-b1a5-9b65bd644da3', protocol='range'}
2022-06-15 23:13:04 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:13:04 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:13:04 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=108, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:15:29 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:15:29 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:15:29 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:15:29 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655309729696
2022-06-15 23:15:29 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:15:30 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:15:30 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:15:30 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:15:30 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:15:34 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=61, memberId='demo-6e820b6e-ebc5-4e54-8469-04c746c20829', protocol='range'}
2022-06-15 23:15:34 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 61: {demo-6e820b6e-ebc5-4e54-8469-04c746c20829=Assignment(partitions=[customer-0])}
2022-06-15 23:15:34 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=61, memberId='demo-6e820b6e-ebc5-4e54-8469-04c746c20829', protocol='range'}
2022-06-15 23:15:34 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:15:34 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:15:34 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=168, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:19:03 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:19:03 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:19:03 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:19:03 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655309943692
2022-06-15 23:19:03 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:19:04 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:19:04 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:19:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:19:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:19:04 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=63, memberId='demo-88581975-7abe-4f6e-aff8-673d022a09fb', protocol='range'}
2022-06-15 23:19:04 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 63: {demo-88581975-7abe-4f6e-aff8-673d022a09fb=Assignment(partitions=[customer-0])}
2022-06-15 23:19:04 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=63, memberId='demo-88581975-7abe-4f6e-aff8-673d022a09fb', protocol='range'}
2022-06-15 23:19:04 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:19:04 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:19:04 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=168, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:19:22 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:19:22 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:19:22 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:19:22 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655309962897
2022-06-15 23:19:22 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:19:23 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:19:23 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:19:23 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:19:23 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:19:26 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=64, memberId='demo-fcd29856-05f8-464f-9c9e-1c1244626d57', protocol='range'}
2022-06-15 23:19:26 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 64: {demo-fcd29856-05f8-464f-9c9e-1c1244626d57=Assignment(partitions=[customer-0])}
2022-06-15 23:19:26 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=64, memberId='demo-fcd29856-05f8-464f-9c9e-1c1244626d57', protocol='range'}
2022-06-15 23:19:26 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:19:26 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:19:26 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=168, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:20:50 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-15 23:20:50 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:20:50 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:20:50 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655310050463
2022-06-15 23:20:50 [main] INFO  CSVProducer:27 - Starting load...
2022-06-15 23:20:50 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:20:51 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-15 23:20:51 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-15 23:20:51 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-15 23:20:51 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-15 23:20:51 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-15 23:20:51 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-15 23:20:51 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-15 23:20:51 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 23:20:51 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 23:20:51 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 23:20:51 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-15 23:20:51 [main] INFO  CSVProducer:41 - Finish
2022-06-15 23:21:07 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:21:07 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:21:07 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:21:07 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655310067196
2022-06-15 23:21:07 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:21:07 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:21:07 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:21:07 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:21:07 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:21:07 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=66, memberId='demo-bc6eba5f-825b-4c1e-8a45-850c39cac3d9', protocol='range'}
2022-06-15 23:21:07 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 66: {demo-bc6eba5f-825b-4c1e-8a45-850c39cac3d9=Assignment(partitions=[customer-0])}
2022-06-15 23:21:07 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=66, memberId='demo-bc6eba5f-825b-4c1e-8a45-850c39cac3d9', protocol='range'}
2022-06-15 23:21:07 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:21:07 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:21:07 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=168, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:22:32 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:22:32 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:22:32 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:22:32 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655310152416
2022-06-15 23:22:32 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:22:32 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:22:32 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:22:32 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:22:33 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:22:35 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=67, memberId='demo-3d0b44c0-c389-47b7-8b5d-66f83d60b191', protocol='range'}
2022-06-15 23:22:35 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 67: {demo-3d0b44c0-c389-47b7-8b5d-66f83d60b191=Assignment(partitions=[customer-0])}
2022-06-15 23:22:35 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=67, memberId='demo-3d0b44c0-c389-47b7-8b5d-66f83d60b191', protocol='range'}
2022-06-15 23:22:35 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:22:35 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:22:35 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:22:42 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-15 23:22:42 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-3d0b44c0-c389-47b7-8b5d-66f83d60b191 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-15 23:22:42 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 23:22:42 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 23:22:42 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 23:22:42 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-15 23:30:27 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:30:27 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:30:27 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:30:27 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655310627401
2022-06-15 23:30:27 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:30:27 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:30:27 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:30:27 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:30:27 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:30:27 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=69, memberId='demo-0abc5158-a0cc-4af3-ae1d-c1b4d70d7ebb', protocol='range'}
2022-06-15 23:30:27 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 69: {demo-0abc5158-a0cc-4af3-ae1d-c1b4d70d7ebb=Assignment(partitions=[customer-0])}
2022-06-15 23:30:28 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=69, memberId='demo-0abc5158-a0cc-4af3-ae1d-c1b4d70d7ebb', protocol='range'}
2022-06-15 23:30:28 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:30:28 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:30:28 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:30:37 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-15 23:30:37 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-0abc5158-a0cc-4af3-ae1d-c1b4d70d7ebb sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-15 23:30:37 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 23:30:37 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 23:30:37 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 23:30:37 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-15 23:30:51 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:30:51 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:30:51 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:30:51 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655310651586
2022-06-15 23:30:51 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:30:52 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:30:52 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:30:52 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:30:52 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:30:52 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=71, memberId='demo-f997daff-fb40-4923-97d2-0b54f017daf5', protocol='range'}
2022-06-15 23:30:52 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 71: {demo-f997daff-fb40-4923-97d2-0b54f017daf5=Assignment(partitions=[customer-0])}
2022-06-15 23:30:52 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=71, memberId='demo-f997daff-fb40-4923-97d2-0b54f017daf5', protocol='range'}
2022-06-15 23:30:52 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:30:52 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:30:52 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:31:46 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:31:46 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:31:46 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:31:46 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655310706833
2022-06-15 23:31:46 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:31:47 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:31:47 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:31:47 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:31:47 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:31:47 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=73, memberId='demo-b8cd832c-f2e4-404a-b8d8-09d8fb7a5c33', protocol='range'}
2022-06-15 23:31:47 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 73: {demo-b8cd832c-f2e4-404a-b8d8-09d8fb7a5c33=Assignment(partitions=[customer-0])}
2022-06-15 23:31:47 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=73, memberId='demo-b8cd832c-f2e4-404a-b8d8-09d8fb7a5c33', protocol='range'}
2022-06-15 23:31:47 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:31:47 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:31:47 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:35:57 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:35:57 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:35:57 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:35:57 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655310957710
2022-06-15 23:35:57 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:35:58 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:35:58 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:35:58 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:35:58 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:36:02 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=74, memberId='demo-7f717452-93d0-4f03-8604-834ac38f07da', protocol='range'}
2022-06-15 23:36:02 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 74: {demo-7f717452-93d0-4f03-8604-834ac38f07da=Assignment(partitions=[customer-0])}
2022-06-15 23:36:02 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=74, memberId='demo-7f717452-93d0-4f03-8604-834ac38f07da', protocol='range'}
2022-06-15 23:36:02 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:36:02 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:36:02 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:38:38 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:38:38 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:38:38 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:38:38 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655311118538
2022-06-15 23:38:38 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:38:39 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:38:39 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:38:39 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:38:39 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:38:42 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=75, memberId='demo-2d333834-1f70-4378-9e06-8a9f2b240600', protocol='range'}
2022-06-15 23:38:42 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 75: {demo-2d333834-1f70-4378-9e06-8a9f2b240600=Assignment(partitions=[customer-0])}
2022-06-15 23:38:42 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=75, memberId='demo-2d333834-1f70-4378-9e06-8a9f2b240600', protocol='range'}
2022-06-15 23:38:42 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:38:42 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:38:42 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:38:48 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-15 23:38:48 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-2d333834-1f70-4378-9e06-8a9f2b240600 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-15 23:38:48 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 23:38:48 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 23:38:48 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 23:38:48 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-15 23:39:17 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:39:17 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:39:17 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:39:17 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655311157244
2022-06-15 23:39:17 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:39:17 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:39:17 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:39:17 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:39:17 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:39:17 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=77, memberId='demo-f5bd33c2-0394-4caa-b414-d095449cb066', protocol='range'}
2022-06-15 23:39:17 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 77: {demo-f5bd33c2-0394-4caa-b414-d095449cb066=Assignment(partitions=[customer-0])}
2022-06-15 23:39:17 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=77, memberId='demo-f5bd33c2-0394-4caa-b414-d095449cb066', protocol='range'}
2022-06-15 23:39:17 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:39:17 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:39:17 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-15 23:39:17 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-15 23:39:17 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-f5bd33c2-0394-4caa-b414-d095449cb066 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-15 23:39:17 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-15 23:39:17 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-15 23:39:17 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-15 23:39:17 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-15 23:41:02 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-15 23:41:02 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-15 23:41:02 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-15 23:41:02 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655311262873
2022-06-15 23:41:02 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-15 23:41:03 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-15 23:41:03 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-15 23:41:03 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:41:03 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-15 23:41:03 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=79, memberId='demo-0b38bf7d-e6cd-4340-a91a-d497f96fecb5', protocol='range'}
2022-06-15 23:41:03 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 79: {demo-0b38bf7d-e6cd-4340-a91a-d497f96fecb5=Assignment(partitions=[customer-0])}
2022-06-15 23:41:03 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=79, memberId='demo-0b38bf7d-e6cd-4340-a91a-d497f96fecb5', protocol='range'}
2022-06-15 23:41:03 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-15 23:41:03 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-15 23:41:03 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 15:50:59 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.17.80.20]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 15:50:59 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 0 ms.
2022-06-16 15:50:59 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 15:50:59 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 15:50:59 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 15:50:59 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 15:51:14 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.17.80.20:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 15:51:14 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 15:51:14 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 15:51:14 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655369474191
2022-06-16 15:51:14 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 15:51:14 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: FdduLLCNRxGthoLJScIhaQ
2022-06-16 15:51:14 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 15:51:14 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 15:51:14 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 15:51:14 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 15:51:14 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 15:51:14 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 15:51:14 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 15:51:14 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 15:51:14 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 15:51:14 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 15:51:14 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 15:51:14 [main] INFO  CSVProducer:41 - Finish
2022-06-16 15:53:28 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 15:53:28 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 15:53:28 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 15:53:28 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655369608823
2022-06-16 15:53:28 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 15:53:29 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:29 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:29 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:29 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:29 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:29 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:29 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:29 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:30 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:30 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:30 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:30 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:31 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:31 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:33 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:33 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:34 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:34 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:34 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:34 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:36 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:36 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:37 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:37 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:37 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:37 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:39 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:39 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:40 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:40 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:41 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:41 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:41 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:41 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:42 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:42 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:43 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:43 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:45 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:45 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:46 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:46 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:47 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:47 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:48 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:48 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:49 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:49 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:50 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:50 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:50 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:50 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:51 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:51 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:52 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:52 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:53 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:53 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:54 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:54 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:56 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:56 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:56 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:56 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:57 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:57 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:53:59 [main] WARN  NetworkClient:776 - [Consumer clientId=demo, groupId=test-consumer-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2022-06-16 15:53:59 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2022-06-16 15:54:04 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.17.80.20:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 15:54:04 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 15:54:04 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 15:54:04 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655369644216
2022-06-16 15:54:04 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer_phannt8
2022-06-16 15:54:04 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: FdduLLCNRxGthoLJScIhaQ
2022-06-16 15:54:04 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator 172.17.80.20:9092 (id: 2147483647 rack: null)
2022-06-16 15:54:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 15:54:04 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 15:54:04 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=7, memberId='demo-4bd24396-c8c6-4f0d-9621-16b52b821b92', protocol='range'}
2022-06-16 15:54:04 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 7: {demo-4bd24396-c8c6-4f0d-9621-16b52b821b92=Assignment(partitions=[customer_phannt8-0])}
2022-06-16 15:54:04 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=7, memberId='demo-4bd24396-c8c6-4f0d-9621-16b52b821b92', protocol='range'}
2022-06-16 15:54:04 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer_phannt8-0])
2022-06-16 15:54:04 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer_phannt8-0
2022-06-16 15:54:04 [main] INFO  ConsumerCoordinator:1362 - [Consumer clientId=demo, groupId=test-consumer-group] Found no committed offset for partition customer_phannt8-0
2022-06-16 15:54:04 [main] INFO  SubscriptionState:398 - [Consumer clientId=demo, groupId=test-consumer-group] Resetting offset for partition customer_phannt8-0 to position FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.17.80.20:9092 (id: 0 rack: null)], epoch=0}}.
2022-06-16 22:14:25 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:14:25 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:14:25 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:14:25 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655392465704
2022-06-16 22:14:25 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:14:26 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:14:26 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:14:26 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:14:26 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:14:26 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:14:26 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:14:26 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:14:26 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:14:26 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:14:26 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:14:26 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:14:26 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:14:26 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:15:34 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:15:34 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:15:34 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:15:34 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655392534571
2022-06-16 22:15:34 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:15:35 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:15:35 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:15:35 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:15:35 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:15:35 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=81, memberId='demo-9c8186fa-4aaa-45d5-b2f9-d03cb8094f84', protocol='range'}
2022-06-16 22:15:35 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 81: {demo-9c8186fa-4aaa-45d5-b2f9-d03cb8094f84=Assignment(partitions=[customer-0])}
2022-06-16 22:15:35 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=81, memberId='demo-9c8186fa-4aaa-45d5-b2f9-d03cb8094f84', protocol='range'}
2022-06-16 22:15:35 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:15:35 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:15:35 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=174, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:18:38 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [172.17.80.20:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:18:39 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:18:39 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:18:39 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655392719113
2022-06-16 22:18:39 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer_phannt8
2022-06-16 22:18:49 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker 172.17.80.20:9092 (id: -1 rack: null) disconnected
2022-06-16 22:19:07 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker 172.17.80.20:9092 (id: -1 rack: null) disconnected
2022-06-16 22:19:37 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker 172.17.80.20:9092 (id: -1 rack: null) disconnected
2022-06-16 22:20:09 [main] WARN  NetworkClient:1060 - [Consumer clientId=demo, groupId=test-consumer-group] Bootstrap broker 172.17.80.20:9092 (id: -1 rack: null) disconnected
2022-06-16 22:20:21 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:20:22 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:20:22 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:20:22 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655392822077
2022-06-16 22:20:22 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:20:22 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:20:22 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:20:22 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:20:22 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:20:22 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=83, memberId='demo-2bbaebe5-3b55-4dc8-95d4-c69f2412c5a0', protocol='range'}
2022-06-16 22:20:22 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 83: {demo-2bbaebe5-3b55-4dc8-95d4-c69f2412c5a0=Assignment(partitions=[customer-0])}
2022-06-16 22:20:22 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=83, memberId='demo-2bbaebe5-3b55-4dc8-95d4-c69f2412c5a0', protocol='range'}
2022-06-16 22:20:22 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:20:22 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:20:22 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=180, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:22:53 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:22:53 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:22:53 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:22:53 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655392973450
2022-06-16 22:22:53 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:22:53 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:22:53 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:22:53 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:22:54 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:22:54 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=85, memberId='demo-42c16b6b-19ef-4f0d-8257-9fffd3c7c12f', protocol='range'}
2022-06-16 22:22:54 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 85: {demo-42c16b6b-19ef-4f0d-8257-9fffd3c7c12f=Assignment(partitions=[customer-0])}
2022-06-16 22:22:54 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=85, memberId='demo-42c16b6b-19ef-4f0d-8257-9fffd3c7c12f', protocol='range'}
2022-06-16 22:22:54 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:22:54 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:22:54 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=180, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:23:34 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:23:34 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:23:34 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:23:34 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393014919
2022-06-16 22:23:34 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:23:35 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:23:35 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:23:35 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:23:35 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:23:40 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=86, memberId='demo-303f044a-ebce-43ae-a03a-2b094d2baad3', protocol='range'}
2022-06-16 22:23:40 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 86: {demo-303f044a-ebce-43ae-a03a-2b094d2baad3=Assignment(partitions=[customer-0])}
2022-06-16 22:23:40 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=86, memberId='demo-303f044a-ebce-43ae-a03a-2b094d2baad3', protocol='range'}
2022-06-16 22:23:40 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:23:40 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:23:40 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=180, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:25:17 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:25:17 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:25:17 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:25:17 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393117532
2022-06-16 22:25:17 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:25:18 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:25:18 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:25:18 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:25:18 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:25:18 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=88, memberId='demo-3cfb10de-c949-4fda-b5f0-75b3987f84ba', protocol='range'}
2022-06-16 22:25:18 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 88: {demo-3cfb10de-c949-4fda-b5f0-75b3987f84ba=Assignment(partitions=[customer-0])}
2022-06-16 22:25:18 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=88, memberId='demo-3cfb10de-c949-4fda-b5f0-75b3987f84ba', protocol='range'}
2022-06-16 22:25:18 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:25:18 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:25:18 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=180, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:29:10 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:29:11 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:29:11 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:29:11 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393351055
2022-06-16 22:29:11 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:29:17 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:29:17 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:29:17 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:29:17 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393357887
2022-06-16 22:29:17 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:29:18 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:29:18 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:29:18 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:29:18 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:29:18 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:29:18 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:29:18 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:29:18 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:29:38 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:29:38 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:29:38 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:29:38 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393378724
2022-06-16 22:29:38 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:29:39 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:29:39 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:29:39 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:29:39 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:29:39 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=90, memberId='demo-d85587f2-d0c8-4a04-890e-7b82055e8bc5', protocol='range'}
2022-06-16 22:29:39 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 90: {demo-d85587f2-d0c8-4a04-890e-7b82055e8bc5=Assignment(partitions=[customer-0])}
2022-06-16 22:29:39 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=90, memberId='demo-d85587f2-d0c8-4a04-890e-7b82055e8bc5', protocol='range'}
2022-06-16 22:29:39 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:29:39 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:29:39 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=180, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:30:12 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:30:12 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:30:12 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:30:12 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393412287
2022-06-16 22:30:12 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:30:12 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:30:12 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:30:12 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:30:12 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:30:12 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:30:12 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:30:12 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:30:12 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:30:21 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:30:21 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:30:21 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:30:21 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393421280
2022-06-16 22:30:21 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:30:21 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:30:21 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:30:21 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:30:21 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:30:21 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=92, memberId='demo-ac95a21f-be0b-43ef-a9f7-0a0ec225b263', protocol='range'}
2022-06-16 22:30:21 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 92: {demo-ac95a21f-be0b-43ef-a9f7-0a0ec225b263=Assignment(partitions=[customer-0])}
2022-06-16 22:30:21 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=92, memberId='demo-ac95a21f-be0b-43ef-a9f7-0a0ec225b263', protocol='range'}
2022-06-16 22:30:21 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:30:21 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:30:21 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=196, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:30:48 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:30:48 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:30:48 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:30:48 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393448880
2022-06-16 22:30:48 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:30:49 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:30:49 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:30:49 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:30:49 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:30:49 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:30:49 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:30:49 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:30:49 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:31:06 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:31:06 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:31:06 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:31:06 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393466250
2022-06-16 22:31:06 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:31:06 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:31:06 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:31:06 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:31:06 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:31:06 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=94, memberId='demo-f02ec8b3-a3fa-42f6-95c7-1e547c616221', protocol='range'}
2022-06-16 22:31:06 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 94: {demo-f02ec8b3-a3fa-42f6-95c7-1e547c616221=Assignment(partitions=[customer-0])}
2022-06-16 22:31:06 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=94, memberId='demo-f02ec8b3-a3fa-42f6-95c7-1e547c616221', protocol='range'}
2022-06-16 22:31:06 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:31:06 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:31:06 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=212, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:32:36 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:32:36 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:32:36 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:32:36 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393556830
2022-06-16 22:32:36 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:32:37 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:32:37 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:32:37 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:32:37 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:32:37 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:32:37 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:32:37 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:32:37 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:33:02 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:33:02 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:33:02 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:33:02 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393582440
2022-06-16 22:33:02 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:33:02 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:33:02 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:33:02 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:33:03 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:33:03 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=96, memberId='demo-8b97e721-3a99-4f73-a172-80f299a72303', protocol='range'}
2022-06-16 22:33:03 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 96: {demo-8b97e721-3a99-4f73-a172-80f299a72303=Assignment(partitions=[customer-0])}
2022-06-16 22:33:03 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=96, memberId='demo-8b97e721-3a99-4f73-a172-80f299a72303', protocol='range'}
2022-06-16 22:33:03 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:33:03 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:33:03 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=228, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:38:09 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:38:09 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:38:09 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:38:09 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393889853
2022-06-16 22:38:09 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:38:10 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:38:10 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:38:10 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:38:10 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:38:10 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:38:10 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:38:10 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:38:10 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:38:19 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:38:19 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:38:19 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:38:19 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655393899894
2022-06-16 22:38:19 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:38:20 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:38:20 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:38:20 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:38:20 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:38:20 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=98, memberId='demo-99687564-0fb0-4e2c-8838-b58d1fa9dba8', protocol='range'}
2022-06-16 22:38:20 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 98: {demo-99687564-0fb0-4e2c-8838-b58d1fa9dba8=Assignment(partitions=[customer-0])}
2022-06-16 22:38:20 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=98, memberId='demo-99687564-0fb0-4e2c-8838-b58d1fa9dba8', protocol='range'}
2022-06-16 22:38:20 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:38:20 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:38:20 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=244, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:46:53 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:46:54 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:46:54 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:46:54 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394414070
2022-06-16 22:46:54 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:46:54 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:46:54 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:46:54 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:46:54 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:46:54 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:46:54 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:46:54 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:46:54 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:47:13 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:47:13 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:47:13 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:47:13 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394433548
2022-06-16 22:47:13 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:47:14 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:47:14 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:47:14 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:47:14 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:47:14 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=100, memberId='demo-76f0c3b6-4fb1-4930-934f-b7e5029d01b2', protocol='range'}
2022-06-16 22:47:14 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 100: {demo-76f0c3b6-4fb1-4930-934f-b7e5029d01b2=Assignment(partitions=[customer-0])}
2022-06-16 22:47:14 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=100, memberId='demo-76f0c3b6-4fb1-4930-934f-b7e5029d01b2', protocol='range'}
2022-06-16 22:47:14 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:47:14 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:47:14 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=260, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:47:46 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:47:46 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:47:46 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:47:46 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394466424
2022-06-16 22:47:46 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:47:46 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:47:46 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:47:46 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:47:47 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:47:49 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=101, memberId='demo-40345b39-fbd7-4e33-990e-7f15b6cfb848', protocol='range'}
2022-06-16 22:47:49 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 101: {demo-40345b39-fbd7-4e33-990e-7f15b6cfb848=Assignment(partitions=[customer-0])}
2022-06-16 22:47:49 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=101, memberId='demo-40345b39-fbd7-4e33-990e-7f15b6cfb848', protocol='range'}
2022-06-16 22:47:49 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:47:49 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:47:49 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=276, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:47:58 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:47:58 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:47:58 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:47:58 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394478517
2022-06-16 22:47:58 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:47:59 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:47:59 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:47:59 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:47:59 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:47:59 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:47:59 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:47:59 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:47:59 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:52:08 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:52:08 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:52:08 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:52:08 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394728683
2022-06-16 22:52:08 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:52:09 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:52:09 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:52:09 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:52:09 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:52:09 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=103, memberId='demo-9785e7a8-16f4-41d0-aa7c-78327c498dd6', protocol='range'}
2022-06-16 22:52:09 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 103: {demo-9785e7a8-16f4-41d0-aa7c-78327c498dd6=Assignment(partitions=[customer-0])}
2022-06-16 22:52:09 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=103, memberId='demo-9785e7a8-16f4-41d0-aa7c-78327c498dd6', protocol='range'}
2022-06-16 22:52:09 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:52:09 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:52:09 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=276, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:52:09 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-16 22:52:09 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-9785e7a8-16f4-41d0-aa7c-78327c498dd6 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-16 22:52:09 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:52:09 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:52:09 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:52:09 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-16 22:52:43 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:52:43 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:52:43 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:52:43 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394763379
2022-06-16 22:52:43 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:52:43 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:52:43 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:52:43 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:52:44 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:52:44 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:52:44 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:52:44 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:52:44 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:52:51 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:52:51 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:52:51 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:52:51 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394771805
2022-06-16 22:52:51 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:52:52 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:52:52 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:52:52 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:52:52 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:52:52 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=105, memberId='demo-01a413a1-4660-4646-b22e-fc0e32959c02', protocol='range'}
2022-06-16 22:52:52 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 105: {demo-01a413a1-4660-4646-b22e-fc0e32959c02=Assignment(partitions=[customer-0])}
2022-06-16 22:52:52 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=105, memberId='demo-01a413a1-4660-4646-b22e-fc0e32959c02', protocol='range'}
2022-06-16 22:52:52 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:52:52 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:52:52 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=292, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:52:52 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-16 22:52:52 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-01a413a1-4660-4646-b22e-fc0e32959c02 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-16 22:52:52 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:52:52 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:52:52 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:52:52 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-16 22:54:15 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:54:15 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:54:15 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:54:15 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394855479
2022-06-16 22:54:15 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:54:15 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:54:15 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:54:16 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:54:16 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:54:16 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=107, memberId='demo-401297f2-829b-4502-b7c0-aec8e5787d86', protocol='range'}
2022-06-16 22:54:16 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 107: {demo-401297f2-829b-4502-b7c0-aec8e5787d86=Assignment(partitions=[customer-0])}
2022-06-16 22:54:16 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=107, memberId='demo-401297f2-829b-4502-b7c0-aec8e5787d86', protocol='range'}
2022-06-16 22:54:16 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:54:16 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:54:16 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=308, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:54:16 [main] INFO  ConsumerCoordinator:307 - [Consumer clientId=demo, groupId=test-consumer-group] Revoke previously assigned partitions customer-0
2022-06-16 22:54:16 [main] INFO  AbstractCoordinator:1045 - [Consumer clientId=demo, groupId=test-consumer-group] Member demo-401297f2-829b-4502-b7c0-aec8e5787d86 sending LeaveGroup request to coordinator MTD-phannt8:9092 (id: 2147483647 rack: null) due to the consumer is being closed
2022-06-16 22:54:16 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:54:16 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:54:16 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:54:16 [main] INFO  AppInfoParser:83 - App info kafka.consumer for demo unregistered
2022-06-16 22:54:28 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:54:28 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:54:28 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:54:28 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394868637
2022-06-16 22:54:28 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:54:29 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:54:29 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:54:29 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:54:29 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:54:29 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=109, memberId='demo-487c5e32-6eec-4079-addc-d13b415aaa68', protocol='range'}
2022-06-16 22:54:29 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 109: {demo-487c5e32-6eec-4079-addc-d13b415aaa68=Assignment(partitions=[customer-0])}
2022-06-16 22:54:29 [main] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=109, memberId='demo-487c5e32-6eec-4079-addc-d13b415aaa68', protocol='range'}
2022-06-16 22:54:29 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:54:29 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:54:29 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=308, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
2022-06-16 22:54:41 [main] INFO  ProducerConfig:372 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2022-06-16 22:54:42 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:54:42 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:54:42 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394882101
2022-06-16 22:54:42 [main] INFO  CSVProducer:27 - Starting load...
2022-06-16 22:54:42 [kafka-producer-network-thread | demo] INFO  Metadata:279 - [Producer clientId=demo] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - id,num_order,age,telephone
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 1,120,22,0367716286
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 2,90,45,0379160207
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 3,145,34,0399538068
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 4,300,18,0387006279
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 5,130,10,0373543099
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 6,90,17,0336528479
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 7,400,30,0347597599
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 8,10,31,0398290980
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 9,230,15,0375667337
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 10,60,14,0326138799
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 11,105,9,0344623488
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 12,222,40,0352372889
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 13,78,51,0867556771
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 14,123,19,0376130794
2022-06-16 22:54:42 [main] INFO  CSVProducer:35 - 15,56,13,0372850979
2022-06-16 22:54:42 [main] INFO  KafkaProducer:1204 - [Producer clientId=demo] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2022-06-16 22:54:42 [main] INFO  Metrics:659 - Metrics scheduler closed
2022-06-16 22:54:42 [main] INFO  Metrics:663 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-06-16 22:54:42 [main] INFO  Metrics:669 - Metrics reporters closed
2022-06-16 22:54:42 [main] INFO  AppInfoParser:83 - App info kafka.producer for demo unregistered
2022-06-16 22:54:42 [main] INFO  CSVProducer:41 - Finish
2022-06-16 22:54:49 [main] INFO  ConsumerConfig:372 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = demo
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2022-06-16 22:54:49 [main] INFO  AppInfoParser:119 - Kafka version: 2.8.1
2022-06-16 22:54:49 [main] INFO  AppInfoParser:120 - Kafka commitId: 839b886f9b732b15
2022-06-16 22:54:49 [main] INFO  AppInfoParser:121 - Kafka startTimeMs: 1655394889973
2022-06-16 22:54:49 [main] INFO  KafkaConsumer:965 - [Consumer clientId=demo, groupId=test-consumer-group] Subscribed to topic(s): customer
2022-06-16 22:54:50 [main] INFO  Metadata:279 - [Consumer clientId=demo, groupId=test-consumer-group] Cluster ID: EP5EvhmrQQag4oJax7QZEw
2022-06-16 22:54:50 [main] INFO  AbstractCoordinator:850 - [Consumer clientId=demo, groupId=test-consumer-group] Discovered group coordinator MTD-phannt8:9092 (id: 2147483647 rack: null)
2022-06-16 22:54:50 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:54:50 [main] INFO  AbstractCoordinator:540 - [Consumer clientId=demo, groupId=test-consumer-group] (Re-)joining group
2022-06-16 22:54:50 [main] INFO  AbstractCoordinator:596 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully joined group with generation Generation{generationId=111, memberId='demo-b8c5832e-222d-47ee-a478-20795f9008ec', protocol='range'}
2022-06-16 22:54:50 [main] INFO  ConsumerCoordinator:626 - [Consumer clientId=demo, groupId=test-consumer-group] Finished assignment for group at generation 111: {demo-b8c5832e-222d-47ee-a478-20795f9008ec=Assignment(partitions=[customer-0])}
2022-06-16 22:54:50 [kafka-coordinator-heartbeat-thread | test-consumer-group] INFO  AbstractCoordinator:760 - [Consumer clientId=demo, groupId=test-consumer-group] Successfully synced group in generation Generation{generationId=111, memberId='demo-b8c5832e-222d-47ee-a478-20795f9008ec', protocol='range'}
2022-06-16 22:54:50 [main] INFO  ConsumerCoordinator:276 - [Consumer clientId=demo, groupId=test-consumer-group] Notifying assignor about the new Assignment(partitions=[customer-0])
2022-06-16 22:54:50 [main] INFO  ConsumerCoordinator:288 - [Consumer clientId=demo, groupId=test-consumer-group] Adding newly assigned partitions: customer-0
2022-06-16 22:54:50 [main] INFO  ConsumerCoordinator:820 - [Consumer clientId=demo, groupId=test-consumer-group] Setting offset for partition customer-0 to the committed offset FetchPosition{offset=308, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[MTD-phannt8:9092 (id: 0 rack: null)], epoch=0}}
